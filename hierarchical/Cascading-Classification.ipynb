{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascading Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.0\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import IPython.display as display\n",
    "\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import random\n",
    "#importing module\n",
    "import sys\n",
    "sys.path.insert(0, '../data')\n",
    "from datahandler_cascading import create_dataset\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24999 24999\n"
     ]
    }
   ],
   "source": [
    "with open('../data/filenames.pkl', 'rb') as infile:\n",
    "    filenames = pickle.load(infile)\n",
    "\n",
    "with open('../data/labels.pkl', 'rb') as infile2:\n",
    "    labels = pickle.load(infile2)\n",
    "    \n",
    "print(len(filenames), len(labels))\n",
    "df = pd.concat([pd.Series(filenames, name='filenames'), pd.Series(labels, name='labels')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24998 24998\n"
     ]
    }
   ],
   "source": [
    "with open('../data/filenames_level2.pkl', 'rb') as infile:\n",
    "    filenames2 = pickle.load(infile)\n",
    "\n",
    "with open('../data/labels_level2.pkl', 'rb') as infile2:\n",
    "    labels2 = pickle.load(infile2)\n",
    "\n",
    "print(len(filenames2), len(labels2))\n",
    "df2 = pd.concat([pd.Series(filenames2, name='filenames'), pd.Series(labels2, name='labels2')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df2, on='filenames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data_tate\\A00001_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data_tate\\A00002_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\data_tate\\A00003_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\data_tate\\A00004_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\data_tate\\A00005_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>..\\..\\data_tate\\T13856_8.jpg</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>..\\..\\data_tate\\T13858_8.jpg</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>..\\..\\data_tate\\T13863_8.jpg</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>..\\..\\data_tate\\T13864_8.jpg</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>..\\..\\data_tate\\T13869_8.jpg</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24998 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filenames  \\\n",
       "0      ..\\..\\data_tate\\A00001_8.jpg   \n",
       "1      ..\\..\\data_tate\\A00002_8.jpg   \n",
       "2      ..\\..\\data_tate\\A00003_8.jpg   \n",
       "3      ..\\..\\data_tate\\A00004_8.jpg   \n",
       "4      ..\\..\\data_tate\\A00005_8.jpg   \n",
       "...                             ...   \n",
       "24993  ..\\..\\data_tate\\T13856_8.jpg   \n",
       "24994  ..\\..\\data_tate\\T13858_8.jpg   \n",
       "24995  ..\\..\\data_tate\\T13863_8.jpg   \n",
       "24996  ..\\..\\data_tate\\T13864_8.jpg   \n",
       "24997  ..\\..\\data_tate\\T13869_8.jpg   \n",
       "\n",
       "                                                  labels  \\\n",
       "0      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4      [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...   \n",
       "...                                                  ...   \n",
       "24993  [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "24994  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "24995  [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24996  [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24997  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 labels2  \n",
       "0      [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1      [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2      [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3      [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4      [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
       "...                                                  ...  \n",
       "24993  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24994  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24995  [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24997  [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "\n",
       "[24998 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"full_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "convolution (Convolution)    multiple                  224512    \n",
      "_________________________________________________________________\n",
      "fc (FC)                      multiple                  1266015   \n",
      "_________________________________________________________________\n",
      "embed (Embed)                multiple                  11760     \n",
      "_________________________________________________________________\n",
      "fc_1 (FC)                    multiple                  1331141   \n",
      "=================================================================\n",
      "Total params: 2,833,428\n",
      "Trainable params: 2,832,788\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"partial_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "convolution_1 (Convolution)  multiple                  224512    \n",
      "_________________________________________________________________\n",
      "fc_2 (FC)                    multiple                  1266015   \n",
      "=================================================================\n",
      "Total params: 1,490,527\n",
      "Trainable params: 1,489,887\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "class Convolution(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, shape=(224,224,3), kernel_size=3,\n",
    "                 pool_size=(2,2), activation='relu', padding='same'):\n",
    "        super(Convolution, self).__init__()\n",
    "        self.input_layer = tf.keras.layers.InputLayer(\n",
    "            input_shape = shape,\n",
    "        )\n",
    "        self.conv_layer = tf.keras.layers.Conv2D(\n",
    "            filters = filters[0], \n",
    "            padding = padding,\n",
    "            kernel_size = kernel_size,\n",
    "            activation = activation,\n",
    "            )\n",
    "        self.conv_layer1 = tf.keras.layers.Conv2D(\n",
    "            filters = filters[1],\n",
    "            padding = padding,\n",
    "            kernel_size = kernel_size,\n",
    "            activation = activation,\n",
    "            )\n",
    "        self.conv_layer2 = tf.keras.layers.Conv2D(\n",
    "            filters = filters[1],\n",
    "            padding = padding,\n",
    "            kernel_size = kernel_size,\n",
    "            activation = activation,\n",
    "            )\n",
    "        self.nn_pooling = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size = pool_size,\n",
    "            padding = padding,\n",
    "            strides = (2,2)\n",
    "            )\n",
    "        self.nn_dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.nn_batchnorm = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "        self.nn_batchnorm1 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "        self.nn_batchnorm2 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        activation = self.input_layer(input_features)\n",
    "        activation = self.conv_layer(activation)\n",
    "        activation = self.nn_batchnorm(activation)\n",
    "        activation = self.nn_pooling(activation)\n",
    "        #print(activation.shape)\n",
    "        activation = self.conv_layer1(activation)\n",
    "        activation = self.nn_batchnorm1(activation)\n",
    "        activation = self.nn_pooling(activation)\n",
    "        #print(activation.shape)\n",
    "        activation = self.conv_layer2(activation)\n",
    "        activation = self.nn_batchnorm2(activation)\n",
    "        activation = self.nn_pooling(activation)\n",
    "        #print(activation.shape)\n",
    "        return activation\n",
    "\n",
    "\n",
    "class FC(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(FC, self).__init__()\n",
    "        self.flat = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.keras.layers.Dense(filters[0], activation='relu')\n",
    "        self.dense1 = tf.keras.layers.Dense(filters[1], activation='relu')\n",
    "        self.out = tf.keras.layers.Dense(filters[2], activation='sigmoid')\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        #print(input_features)\n",
    "        activation = self.flat(input_features)\n",
    "        activation = self.dense(activation)\n",
    "        activation = self.dropout(activation)\n",
    "        activation = self.dense1(activation)\n",
    "        #print(activation)\n",
    "        activation = self.dropout(activation)\n",
    "        activation = self.out(activation)\n",
    "        #print(activation)\n",
    "        return activation\n",
    "    \n",
    "    \n",
    "class Embed(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Embed, self).__init__()\n",
    "        self.embed = tf.keras.layers.Embedding(15, 28*28, input_length=1)\n",
    "        self.reshape = tf.keras.layers.Reshape((28,28))\n",
    "        \n",
    "        \n",
    "    def call(self, input_features):\n",
    "        #print(input_features.shape)\n",
    "        activation = tf.argmax(input_features, axis=1)\n",
    "        #print(activation.shape)\n",
    "        activation = self.embed(activation)\n",
    "        #print(activation.shape)\n",
    "        activation = self.reshape(activation)\n",
    "        return activation\n",
    "    \n",
    "\n",
    "class FullModel(tf.keras.Model):\n",
    "    def __init__(self, filters_conv=[64,128], filters_dense=[2000,500,15], filters_dense1=[2000,500,141]):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.convolution = Convolution(filters_conv)\n",
    "        self.dense = FC(filters_dense)\n",
    "        self.embed = Embed()\n",
    "        self.dense1 = FC(filters_dense1)\n",
    "\n",
    "    def call(self, input_features):\n",
    "        activation = self.convolution(input_features)\n",
    "        activation_ = self.dense(activation)\n",
    "        #print(activation.shape)\n",
    "        activation1 = self.embed(activation_)\n",
    "        activation1 = tf.expand_dims(activation1, axis=3)\n",
    "        #print(activation.shape, activation1.shape)\n",
    "        activation2 = tf.concat([activation, activation1], 3)#do something that puts the conv and the embedding together\n",
    "        #print(activation2)\n",
    "        activation2 = self.dense1(activation2)\n",
    "        #print(activation2)\n",
    "        return [activation_, activation2]\n",
    "\n",
    "class PartialModel(tf.keras.Model):\n",
    "    def __init__(self, filters_conv=[64,128], filters_dense=[2000,500,15]):\n",
    "        super(PartialModel, self).__init__()\n",
    "        self.convolution = Convolution(filters_conv)\n",
    "        self.dense = FC(filters_dense)\n",
    "\n",
    "\n",
    "    def call(self, input_features):\n",
    "        activation = self.convolution(input_features)\n",
    "        activation1 = self.dense(activation)\n",
    "        #print(activation.shape, activation1.shape)\n",
    "        return activation1\n",
    "\n",
    "\n",
    "\n",
    "model = FullModel()\n",
    "\n",
    "partial_model = PartialModel()\n",
    "\n",
    "model.build(input_shape=(32, 224, 224, 3))\n",
    "partial_model.build(input_shape=(32, 224, 224, 3))\n",
    "#final_model.build(input_shape=(32,224,224,4))\n",
    "print(model.summary(), partial_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x_train, y_train, _y_train):\n",
    "    loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    loss_binary = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    intermidiate_loss = loss_binary(model(x_train)[0], y_train)\n",
    "    reconstruction_error = loss_object(model(x_train)[1], _y_train)\n",
    "    return tf.math.add(reconstruction_error,intermidiate_loss)\n",
    "\n",
    "\n",
    "def train(loss, model, opt, x_train=None, y_train=None, _y_train=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        gradients = tape.gradient(loss(model, x_train, y_train, _y_train), model.trainable_variables)\n",
    "        #gradients = [grad if grad is not None else tf.zeros_like(var) for var, grad in zip(model.trainable_variables, gradients)]\n",
    "        gradient_variables = zip(gradients, model.trainable_variables)\n",
    "        opt.apply_gradients(gradient_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = list(df['filenames'][:18000])\n",
    "train_y = list(df['labels'][:18000])\n",
    "train_y_ = list(df['labels2'][:18000])\n",
    "val_x = list(df['filenames'][18000:21000])\n",
    "val_y = list(df['labels'][18000:21000])\n",
    "val_y_ = list(df['labels2'][18000:21000])\n",
    "test_x = list(df['filenames'][21000:])\n",
    "test_y = list(df['labels'][21000:])\n",
    "test_y_ = list(df['labels2'][21000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = create_dataset(train_x, train_y, train_y_)\n",
    "val_generator = create_dataset(val_x, val_y, val_y_)\n",
    "test_generator = create_dataset(test_x, test_y, test_y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.4114631414413452, shape=(), dtype=float64)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Mul] name: mul/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-54ecb217f04b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# End epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtrain_loss_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mprec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mtrain_precision_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iter end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-54ecb217f04b>\u001b[0m in \u001b[0;36mprecision\u001b[1;34m(y, y_hat)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgreater\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mpres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1204\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6695\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6696\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6697\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6698\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6699\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Mul] name: mul/"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.enable_eager_execution()\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "opt = tf.keras.optimizers.Adam() #learning_rate=learning_rate: will add in future version\n",
    "num_epochs = 20\n",
    "partial_model = PartialModel()\n",
    "model = FullModel()\n",
    "\n",
    "def precision(y, y_hat):\n",
    "        y_pred = tf.cast(tf.greater(y_hat, 0.5), tf.float32)\n",
    "        tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
    "        fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
    "        pres = tp / (tp + fp + 1e-16)\n",
    "        precision = tf.reduce_mean(pres)\n",
    "        return precision\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for batch in range(len(train_x)//56):\n",
    "        features, labels1, labels2 = next(iter(train_generator))\n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        epoch_accuracy = tf.keras.metrics.Accuracy()\n",
    "        train(loss, model, opt, x_train=features, y_train=labels1, _y_train=labels2)\n",
    "        loss_values = loss(model, x_train=features, y_train=labels1, _y_train=labels2)\n",
    "        print(loss_values)\n",
    "        # End epoch\n",
    "        train_loss_results.append(loss_values)\n",
    "        prec = precision(labels2, model(features)[1])\n",
    "        train_precision_results.append(prec)\n",
    "        print('iter end', batch, prec)\n",
    "    print('epoch end', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
