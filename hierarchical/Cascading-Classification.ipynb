{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascading Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.0\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import IPython.display as display\n",
    "\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import random\n",
    "#importing module\n",
    "import sys\n",
    "sys.path.insert(0, '../data')\n",
    "from datahandler_cascading import create_dataset\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24999 24999\n"
     ]
    }
   ],
   "source": [
    "with open('../data/filenames.pkl', 'rb') as infile:\n",
    "    filenames = pickle.load(infile)\n",
    "\n",
    "with open('../data/labels.pkl', 'rb') as infile2:\n",
    "    labels = pickle.load(infile2)\n",
    "    \n",
    "print(len(filenames), len(labels))\n",
    "df = pd.concat([pd.Series(filenames, name='filenames'), pd.Series(labels, name='labels')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24998 24998\n"
     ]
    }
   ],
   "source": [
    "with open('../data/filenames_level2.pkl', 'rb') as infile:\n",
    "    filenames2 = pickle.load(infile)\n",
    "\n",
    "with open('../data/labels_level2.pkl', 'rb') as infile2:\n",
    "    labels2 = pickle.load(infile2)\n",
    "\n",
    "print(len(filenames2), len(labels2))\n",
    "df2 = pd.concat([pd.Series(filenames2, name='filenames'), pd.Series(labels2, name='labels2')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df2, on='filenames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data_tate\\A00001_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data_tate\\A00002_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\data_tate\\A00003_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\data_tate\\A00004_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\data_tate\\A00005_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>..\\..\\data_tate\\T13856_8.jpg</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>..\\..\\data_tate\\T13858_8.jpg</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>..\\..\\data_tate\\T13863_8.jpg</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>..\\..\\data_tate\\T13864_8.jpg</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>..\\..\\data_tate\\T13869_8.jpg</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24998 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filenames  \\\n",
       "0      ..\\..\\data_tate\\A00001_8.jpg   \n",
       "1      ..\\..\\data_tate\\A00002_8.jpg   \n",
       "2      ..\\..\\data_tate\\A00003_8.jpg   \n",
       "3      ..\\..\\data_tate\\A00004_8.jpg   \n",
       "4      ..\\..\\data_tate\\A00005_8.jpg   \n",
       "...                             ...   \n",
       "24993  ..\\..\\data_tate\\T13856_8.jpg   \n",
       "24994  ..\\..\\data_tate\\T13858_8.jpg   \n",
       "24995  ..\\..\\data_tate\\T13863_8.jpg   \n",
       "24996  ..\\..\\data_tate\\T13864_8.jpg   \n",
       "24997  ..\\..\\data_tate\\T13869_8.jpg   \n",
       "\n",
       "                                                  labels  \\\n",
       "0      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4      [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...   \n",
       "...                                                  ...   \n",
       "24993  [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "24994  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "24995  [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24996  [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24997  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 labels2  \n",
       "0      [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1      [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2      [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3      [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4      [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
       "...                                                  ...  \n",
       "24993  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24994  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24995  [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24997  [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "\n",
       "[24998 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"full_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "convolution (Convolution)    multiple                  224512    \n",
      "_________________________________________________________________\n",
      "fc (FC)                      multiple                  1266015   \n",
      "_________________________________________________________________\n",
      "embed (Embed)                multiple                  11760     \n",
      "_________________________________________________________________\n",
      "fc_1 (FC)                    multiple                  1331141   \n",
      "=================================================================\n",
      "Total params: 2,833,428\n",
      "Trainable params: 2,832,788\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"pretrained_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "fc_2 (FC)                    multiple                  2034015   \n",
      "_________________________________________________________________\n",
      "embed_1 (Embed)              multiple                  735       \n",
      "_________________________________________________________________\n",
      "fc_3 (FC)                    multiple                  2099141   \n",
      "=================================================================\n",
      "Total params: 18,848,579\n",
      "Trainable params: 4,133,891\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "class Convolution(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, shape=(224,224,3), kernel_size=3,\n",
    "                 pool_size=(2,2), activation='relu', padding='same'):\n",
    "        super(Convolution, self).__init__()\n",
    "        self.input_layer = tf.keras.layers.InputLayer(\n",
    "            input_shape = shape,\n",
    "        )\n",
    "        self.conv_layer = tf.keras.layers.Conv2D(\n",
    "            filters = filters[0], \n",
    "            padding = padding,\n",
    "            kernel_size = kernel_size,\n",
    "            activation = activation,\n",
    "            )\n",
    "        self.conv_layer1 = tf.keras.layers.Conv2D(\n",
    "            filters = filters[1],\n",
    "            padding = padding,\n",
    "            kernel_size = kernel_size,\n",
    "            activation = activation,\n",
    "            )\n",
    "        self.conv_layer2 = tf.keras.layers.Conv2D(\n",
    "            filters = filters[1],\n",
    "            padding = padding,\n",
    "            kernel_size = kernel_size,\n",
    "            activation = activation,\n",
    "            )\n",
    "        self.nn_pooling = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size = pool_size,\n",
    "            padding = padding,\n",
    "            strides = (2,2)\n",
    "            )\n",
    "        self.nn_dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.nn_batchnorm = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "        self.nn_batchnorm1 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "        self.nn_batchnorm2 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        activation = self.input_layer(input_features)\n",
    "        activation = self.conv_layer(activation)\n",
    "        activation = self.nn_batchnorm(activation)\n",
    "        activation = self.nn_pooling(activation)\n",
    "        #print(activation.shape)\n",
    "        activation = self.conv_layer1(activation)\n",
    "        activation = self.nn_batchnorm1(activation)\n",
    "        activation = self.nn_pooling(activation)\n",
    "        #print(activation.shape)\n",
    "        activation = self.conv_layer2(activation)\n",
    "        activation = self.nn_batchnorm2(activation)\n",
    "        activation = self.nn_pooling(activation)\n",
    "        #print(activation.shape)\n",
    "        return activation\n",
    "\n",
    "\n",
    "class FC(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(FC, self).__init__()\n",
    "        self.flat = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.keras.layers.Dense(filters[0], activation='relu')\n",
    "        self.dense1 = tf.keras.layers.Dense(filters[1], activation='relu')\n",
    "        self.out = tf.keras.layers.Dense(filters[2], activation='sigmoid')\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        #print(input_features)\n",
    "        activation = self.flat(input_features)\n",
    "        activation = self.dense(activation)\n",
    "        activation = self.dropout(activation)\n",
    "        activation = self.dense1(activation)\n",
    "        #print(activation)\n",
    "        activation = self.dropout(activation)\n",
    "        activation = self.out(activation)\n",
    "        #print(activation)\n",
    "        return activation\n",
    "    \n",
    "    \n",
    "class Embed(tf.keras.layers.Layer):\n",
    "    def __init__(self, emb_dim=28):\n",
    "        super(Embed, self).__init__()\n",
    "        self.embed = tf.keras.layers.Embedding(15, emb_dim*emb_dim, input_length=1)\n",
    "        self.reshape = tf.keras.layers.Reshape((emb_dim,emb_dim))\n",
    "        \n",
    "        \n",
    "    def call(self, input_features):\n",
    "        #print(input_features.shape)\n",
    "        activation = tf.argmax(input_features, axis=1)\n",
    "        #print(activation.shape)\n",
    "        activation = self.embed(activation)\n",
    "        #print(activation.shape)\n",
    "        activation = self.reshape(activation)\n",
    "        return activation\n",
    "    \n",
    "\n",
    "class FullModel(tf.keras.Model):\n",
    "    def __init__(self, emb_dim=28, filters_conv=[64,128], filters_dense=[2000,500,15], filters_dense1=[2000,500,141]):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.convolution = Convolution(filters_conv)\n",
    "        self.dense = FC(filters_dense)\n",
    "        self.embed = Embed(emb_dim)\n",
    "        self.dense1 = FC(filters_dense1)\n",
    "\n",
    "    def call(self, input_features):\n",
    "        activation = self.convolution(input_features)\n",
    "        activation_ = self.dense(activation)\n",
    "        #print(activation.shape)\n",
    "        activation1 = self.embed(activation_)\n",
    "        activation1 = tf.expand_dims(activation1, axis=3)\n",
    "        #print(activation.shape, activation1.shape)\n",
    "        activation2 = tf.concat([activation, activation1], 3)#do something that puts the conv and the embedding together\n",
    "        #print(activation2)\n",
    "        activation2 = self.dense1(activation2)\n",
    "        #print(activation2)\n",
    "        return [activation_, activation2]\n",
    "\n",
    "class PretrainedModel(tf.keras.Model):\n",
    "    def __init__(self, emb_dim=7, filters_dense=[2000,500,15], filters_dense1=[2000,500,141]):\n",
    "        super(PretrainedModel, self).__init__()\n",
    "        self.convolution = tf.keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "        self.convolution.trainable = False\n",
    "        self.dense = FC(filters_dense)\n",
    "        self.embed = Embed(emb_dim)\n",
    "        self.dense1 = FC(filters_dense1)\n",
    "\n",
    "    def call(self, input_features):\n",
    "        activation = self.convolution(input_features)\n",
    "        activation_ = self.dense(activation)\n",
    "        #print(activation.shape)\n",
    "        activation1 = self.embed(activation_)\n",
    "        activation1 = tf.expand_dims(activation1, axis=3)\n",
    "        #print(activation.shape, activation1.shape)\n",
    "        activation2 = tf.concat([activation, activation1], 3)#do something that puts the conv and the embedding together\n",
    "        #print(activation2)\n",
    "        activation2 = self.dense1(activation2)\n",
    "        #print(activation2)\n",
    "        return [activation_, activation2]\n",
    "\n",
    "\n",
    "\n",
    "model = FullModel()\n",
    "\n",
    "pretrained_model = PretrainedModel()\n",
    "\n",
    "model.build(input_shape=(32, 224, 224, 3))\n",
    "pretrained_model.build(input_shape=(32, 224, 224, 3))\n",
    "#final_model.build(input_shape=(32,224,224,4))\n",
    "print(model.summary(), pretrained_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x_train, y_train, _y_train):\n",
    "    loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    loss_binary = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    intermidiate_loss = loss_binary(model(x_train)[0], y_train)\n",
    "    reconstruction_error = loss_object(model(x_train)[1], _y_train)\n",
    "    return tf.math.add(reconstruction_error,intermidiate_loss)\n",
    "\n",
    "\n",
    "def train(loss, model, opt, x_train=None, y_train=None, _y_train=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        gradients = tape.gradient(loss(model, x_train, y_train, _y_train), model.trainable_variables)\n",
    "        gradient_variables = zip(gradients, model.trainable_variables)\n",
    "        opt.apply_gradients(gradient_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = list(df['filenames'][:18000])\n",
    "train_y = list(df['labels'][:18000])\n",
    "train_y_ = list(df['labels2'][:18000])\n",
    "val_x = list(df['filenames'][18000:21000])\n",
    "val_y = list(df['labels'][18000:21000])\n",
    "val_y_ = list(df['labels2'][18000:21000])\n",
    "test_x = list(df['filenames'][21000:])\n",
    "test_y = list(df['labels'][21000:])\n",
    "test_y_ = list(df['labels2'][21000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = create_dataset(train_x, train_y, train_y_)\n",
    "val_generator = create_dataset(val_x, val_y, val_y_)\n",
    "test_generator = create_dataset(test_x, test_y, test_y_, BATCH_SIZE=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.3530805706977844, shape=(), dtype=float64)\n",
      "iter end 0\n",
      "tf.Tensor(1.328610360622406, shape=(), dtype=float64)\n",
      "iter end 1\n",
      "tf.Tensor(1.3138301372528076, shape=(), dtype=float64)\n",
      "iter end 2\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.enable_eager_execution()\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "opt = tf.keras.optimizers.Adam() #learning_rate=learning_rate: will add in future version\n",
    "num_epochs = 1\n",
    "\n",
    "model = PretrainedModel()\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for batch in range(len(train_x)//56):\n",
    "        features, labels1, labels2 = next(iter(train_generator))\n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        epoch_accuracy = tf.keras.metrics.Accuracy()\n",
    "        train(loss, model, opt, x_train=features, y_train=labels1, _y_train=labels2)\n",
    "        loss_values = loss(model, x_train=features, y_train=labels1, _y_train=labels2)\n",
    "        print(loss_values)\n",
    "        train_loss_results.append(loss_values)\n",
    "        print('iter end', batch)\n",
    "    print('epoch end', i)\n",
    "    \n",
    "# Save the weights\n",
    "model.save_weights('./cascading_model_VGG.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Restore the weights\n",
    "model.load_weights('./cascading_model_VGG.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "loss,acc = model.evaluate(test_generator, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter end 0\n",
      "iter end 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[1;34m\"explicit_paddings\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data_format\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1023\u001b[1;33m         \"dilations\", dilations)\n\u001b[0m\u001b[0;32m   1024\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_FallbackException\u001b[0m: Expecting int64_t value for attr strides, got numpy.int32",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-97970dffb4be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mepoch_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mloss_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_y_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iter end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-f7d500886e1c>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[0mactivation_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m#print(activation.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m   1132\u001b[0m           call_from_convolution=False)\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1135\u001b[0m     \u001b[1;31m# copybara:strip_end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m     \u001b[1;31m# copybara:insert return self.conv_op(inp, filter)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m         name=self.name)\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[0;32m   2008\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m                            name=name)\n\u001b[0m\u001b[0;32m   2011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m   1031\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_eager_fallback\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\u001b[0m\n\u001b[0;32m   1127\u001b[0m   explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[0;32m   1128\u001b[0m   _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[1;32m-> 1129\u001b[1;33m                              ctx=_ctx, name=name)\n\u001b[0m\u001b[0;32m   1130\u001b[0m   _execute.record_gradient(\n\u001b[0;32m   1131\u001b[0m       \"Conv2D\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "predictions = []\n",
    "for i in range(1):\n",
    "    for batch in range(len(test_x)):\n",
    "        features, labels1, labels2 = next(iter(test_generator))\n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        epoch_accuracy = tf.keras.metrics.Accuracy()\n",
    "        loss_values = loss(model, x_train=features, y_train=labels1, _y_train=labels2)\n",
    "        predictions.append((model(features)[1].numpy(), labels2.numpy()))\n",
    "        print('iter end', batch)\n",
    "    print('epoch end', i)\n",
    "    \n",
    "with open('./results/predictions_cascading.pkl', 'wb') as outfile:\n",
    "    pickle.dump(predictions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[0.72272587, 0.4591314 , 0.9440781 , 0.9884336 , 0.80037665,\n",
       "          0.7409066 , 0.7884487 , 0.484259  , 0.64152014, 0.8863679 ,\n",
       "          0.4542021 , 0.28712708, 0.316973  , 0.57846975, 0.817062  ,\n",
       "          0.46020132, 0.5939596 , 0.6824794 , 0.3767802 , 0.8362967 ,\n",
       "          0.5920112 , 0.7939452 , 0.83592486, 0.61042714, 0.49375656,\n",
       "          0.51541317, 0.6291097 , 0.54952615, 0.5681636 , 0.7850764 ,\n",
       "          0.52376866, 0.41669416, 0.4884728 , 0.6627628 , 0.5328053 ,\n",
       "          0.74593025, 0.3597852 , 0.7119821 , 0.605677  , 0.51992124,\n",
       "          0.54172736, 0.27221403, 0.41976735, 0.46717072, 0.26417276,\n",
       "          0.32339936, 0.82043767, 0.575533  , 0.5024402 , 0.6294856 ,\n",
       "          0.50769114, 0.65933496, 0.75077516, 0.56084245, 0.5174135 ,\n",
       "          0.48967043, 0.31887782, 0.37403297, 0.5123874 , 0.16325861,\n",
       "          0.2558369 , 0.6294575 , 0.497178  , 0.6497768 , 0.35200062,\n",
       "          0.49529   , 0.51879907, 0.35497546, 0.6276263 , 0.8023348 ,\n",
       "          0.24819574, 0.5343013 , 0.77364355, 0.5099465 , 0.50547236,\n",
       "          0.4499981 , 0.4513435 , 0.449646  , 0.4777562 , 0.7173707 ,\n",
       "          0.6299272 , 0.4597254 , 0.8432131 , 0.7123087 , 0.6908647 ,\n",
       "          0.49912184, 0.36173525, 0.43143556, 0.82480806, 0.68830776,\n",
       "          0.61747   , 0.37639773, 0.33166334, 0.43711933, 0.7606954 ,\n",
       "          0.8389306 , 0.49032348, 0.52608216, 0.7531132 , 0.42350683,\n",
       "          0.69401586, 0.6129596 , 0.6676989 , 0.45002252, 0.65438956,\n",
       "          0.36015633, 0.63867605, 0.45952645, 0.6203051 , 0.6344241 ,\n",
       "          0.37184948, 0.35394984, 0.26802856, 0.6677375 , 0.44015634,\n",
       "          0.5154956 , 0.5318035 , 0.6327356 , 0.40837133, 0.6516445 ,\n",
       "          0.8118042 , 0.52603793, 0.6320522 , 0.5274715 , 0.75509393,\n",
       "          0.6193721 , 0.3335904 , 0.7677357 , 0.6195287 , 0.6346184 ,\n",
       "          0.51281136, 0.691841  , 0.5267629 , 0.6150124 , 0.47729886,\n",
       "          0.63830495, 0.4302977 , 0.76094764, 0.6970294 , 0.4260537 ,\n",
       "          0.6057399 ]], dtype=float32),\n",
       "  array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (array([[0.7233934 , 0.4570135 , 0.94887364, 0.98935723, 0.8072347 ,\n",
       "          0.75269926, 0.7947071 , 0.4813633 , 0.64310247, 0.89504886,\n",
       "          0.44894916, 0.28480196, 0.32151222, 0.59722596, 0.82257664,\n",
       "          0.4659032 , 0.59535086, 0.6881823 , 0.37593132, 0.8421992 ,\n",
       "          0.59053814, 0.799366  , 0.8399638 , 0.5961594 , 0.49774906,\n",
       "          0.5143029 , 0.6351336 , 0.54873765, 0.56991607, 0.79258156,\n",
       "          0.52472496, 0.41598606, 0.48126045, 0.66734767, 0.5291309 ,\n",
       "          0.75664806, 0.35516143, 0.70538104, 0.59996855, 0.5070476 ,\n",
       "          0.5413437 , 0.25577837, 0.4038639 , 0.4689484 , 0.2514311 ,\n",
       "          0.319955  , 0.82426953, 0.5759748 , 0.5103471 , 0.63268316,\n",
       "          0.4998047 , 0.66268885, 0.7447796 , 0.56277376, 0.5235772 ,\n",
       "          0.48891827, 0.3136801 , 0.3752857 , 0.5142496 , 0.15597904,\n",
       "          0.24553093, 0.62709916, 0.48902225, 0.6581425 , 0.34794682,\n",
       "          0.48952934, 0.5308054 , 0.35249978, 0.6301771 , 0.8052353 ,\n",
       "          0.23031521, 0.53232396, 0.7827164 , 0.51878625, 0.5067669 ,\n",
       "          0.45029306, 0.43792555, 0.44886535, 0.47914794, 0.71371126,\n",
       "          0.6266374 , 0.4611219 , 0.849473  , 0.7259043 , 0.6915692 ,\n",
       "          0.49743187, 0.34686646, 0.4375639 , 0.8290877 , 0.67640465,\n",
       "          0.62113094, 0.3723066 , 0.33668953, 0.4545631 , 0.76936203,\n",
       "          0.83996654, 0.49465448, 0.5281967 , 0.75418234, 0.41262498,\n",
       "          0.7015487 , 0.62004846, 0.6725376 , 0.45476475, 0.6680242 ,\n",
       "          0.35686472, 0.6378065 , 0.45767587, 0.6148976 , 0.63320506,\n",
       "          0.36464265, 0.3496527 , 0.26538277, 0.67758286, 0.43776986,\n",
       "          0.51604563, 0.5343639 , 0.6472039 , 0.41180104, 0.66325575,\n",
       "          0.8190896 , 0.5319083 , 0.6230389 , 0.52986395, 0.76980525,\n",
       "          0.6202502 , 0.3243046 , 0.77214587, 0.60699695, 0.6480892 ,\n",
       "          0.50019485, 0.7082311 , 0.52470535, 0.60828745, 0.4754712 ,\n",
       "          0.6624694 , 0.4343818 , 0.7682531 , 0.69786096, 0.41757575,\n",
       "          0.59264743]], dtype=float32),\n",
       "  array([[0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
