{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascading Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import IPython.display as display\n",
    "\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import random\n",
    "#importing module\n",
    "import sys\n",
    "sys.path.insert(0, '../data')\n",
    "from datahandler_cascading import create_dataset\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24999 24999\n"
     ]
    }
   ],
   "source": [
    "with open('../data/filenames.pkl', 'rb') as infile:\n",
    "    filenames = pickle.load(infile)\n",
    "\n",
    "with open('../data/labels.pkl', 'rb') as infile2:\n",
    "    labels = pickle.load(infile2)\n",
    "    \n",
    "print(len(filenames), len(labels))\n",
    "df = pd.concat([pd.Series(filenames, name='filenames'), pd.Series(labels, name='labels')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24998 24998\n"
     ]
    }
   ],
   "source": [
    "with open('../data/filenames_level2.pkl', 'rb') as infile:\n",
    "    filenames2 = pickle.load(infile)\n",
    "\n",
    "with open('../data/labels_level2.pkl', 'rb') as infile2:\n",
    "    labels2 = pickle.load(infile2)\n",
    "\n",
    "print(len(filenames2), len(labels2))\n",
    "df2 = pd.concat([pd.Series(filenames2, name='filenames'), pd.Series(labels2, name='labels2')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df2, on='filenames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data_tate\\A00001_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data_tate\\A00002_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\data_tate\\A00003_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\data_tate\\A00004_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\data_tate\\A00005_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>..\\..\\data_tate\\T13856_8.jpg</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>..\\..\\data_tate\\T13858_8.jpg</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>..\\..\\data_tate\\T13863_8.jpg</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>..\\..\\data_tate\\T13864_8.jpg</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>..\\..\\data_tate\\T13869_8.jpg</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24998 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filenames  \\\n",
       "0      ..\\..\\data_tate\\A00001_8.jpg   \n",
       "1      ..\\..\\data_tate\\A00002_8.jpg   \n",
       "2      ..\\..\\data_tate\\A00003_8.jpg   \n",
       "3      ..\\..\\data_tate\\A00004_8.jpg   \n",
       "4      ..\\..\\data_tate\\A00005_8.jpg   \n",
       "...                             ...   \n",
       "24993  ..\\..\\data_tate\\T13856_8.jpg   \n",
       "24994  ..\\..\\data_tate\\T13858_8.jpg   \n",
       "24995  ..\\..\\data_tate\\T13863_8.jpg   \n",
       "24996  ..\\..\\data_tate\\T13864_8.jpg   \n",
       "24997  ..\\..\\data_tate\\T13869_8.jpg   \n",
       "\n",
       "                                                  labels  \\\n",
       "0      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4      [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...   \n",
       "...                                                  ...   \n",
       "24993  [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "24994  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "24995  [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24996  [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24997  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 labels2  \n",
       "0      [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1      [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2      [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3      [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4      [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
       "...                                                  ...  \n",
       "24993  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24994  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24995  [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24997  [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "\n",
       "[24998 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"full_model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "convolution_24 (Convolution) multiple                  224512    \n",
      "_________________________________________________________________\n",
      "fc_36 (FC)                   multiple                  1266015   \n",
      "_________________________________________________________________\n",
      "embed_12 (Embed)             multiple                  11760     \n",
      "_________________________________________________________________\n",
      "fc_37 (FC)                   multiple                  1331141   \n",
      "=================================================================\n",
      "Total params: 2,833,428\n",
      "Trainable params: 2,832,788\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"partial_model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "convolution_25 (Convolution) multiple                  224512    \n",
      "_________________________________________________________________\n",
      "fc_38 (FC)                   multiple                  1266015   \n",
      "=================================================================\n",
      "Total params: 1,490,527\n",
      "Trainable params: 1,489,887\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "class Convolution(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, shape=(224,224,3), kernel_size=3,\n",
    "                 pool_size=(2,2), activation='relu', padding='same'):\n",
    "        super(Convolution, self).__init__()\n",
    "        self.input_layer = tf.keras.layers.InputLayer(\n",
    "            input_shape = shape,\n",
    "        )\n",
    "        self.conv_layer = tf.keras.layers.Conv2D(\n",
    "            filters = filters[0], \n",
    "            padding = padding,\n",
    "            kernel_size = kernel_size,\n",
    "            activation = activation,\n",
    "            )\n",
    "        self.conv_layer1 = tf.keras.layers.Conv2D(\n",
    "            filters = filters[1],\n",
    "            padding = padding,\n",
    "            kernel_size = kernel_size,\n",
    "            activation = activation,\n",
    "            )\n",
    "        self.conv_layer2 = tf.keras.layers.Conv2D(\n",
    "            filters = filters[1],\n",
    "            padding = padding,\n",
    "            kernel_size = kernel_size,\n",
    "            activation = activation,\n",
    "            )\n",
    "        self.nn_pooling = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size = pool_size,\n",
    "            padding = padding,\n",
    "            strides = (2,2)\n",
    "            )\n",
    "        self.nn_dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.nn_batchnorm = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "        self.nn_batchnorm1 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "        self.nn_batchnorm2 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        activation = self.input_layer(input_features)\n",
    "        activation = self.conv_layer(activation)\n",
    "        activation = self.nn_batchnorm(activation)\n",
    "        activation = self.nn_pooling(activation)\n",
    "        #print(activation.shape)\n",
    "        activation = self.conv_layer1(activation)\n",
    "        activation = self.nn_batchnorm1(activation)\n",
    "        activation = self.nn_pooling(activation)\n",
    "        #print(activation.shape)\n",
    "        activation = self.conv_layer2(activation)\n",
    "        activation = self.nn_batchnorm2(activation)\n",
    "        activation = self.nn_pooling(activation)\n",
    "        #print(activation.shape)\n",
    "        return activation\n",
    "\n",
    "\n",
    "class FC(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(FC, self).__init__()\n",
    "        self.flat = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.keras.layers.Dense(filters[0], activation='relu')\n",
    "        self.dense1 = tf.keras.layers.Dense(filters[1], activation='relu')\n",
    "        self.out = tf.keras.layers.Dense(filters[2], activation='sigmoid')\n",
    "\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        activation = self.flat(input_features)\n",
    "        activation = self.dense(activation)\n",
    "        activation = self.dense1(activation)\n",
    "        activation = self.out(activation)\n",
    "        return activation\n",
    "    \n",
    "    \n",
    "class Embed(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Embed, self).__init__()\n",
    "        self.embed = tf.keras.layers.Embedding(15, 28*28, input_length=1)\n",
    "        self.reshape = tf.keras.layers.Reshape((28,28))\n",
    "        \n",
    "        \n",
    "    def call(self, input_features):\n",
    "        #print(input_features.shape)\n",
    "        activation = tf.argmax(input_features, axis=1)\n",
    "        #print(activation.shape)\n",
    "        activation = self.embed(activation)\n",
    "        #print(activation.shape)\n",
    "        activation = self.reshape(activation)\n",
    "        return activation\n",
    "    \n",
    "\n",
    "class FullModel(tf.keras.Model):\n",
    "    def __init__(self, filters_conv=[64,128], filters_dense=[2000,500,15], filters_dense1=[2000,500,141]):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.convolution = Convolution(filters_conv)\n",
    "        self.dense = FC(filters_dense)\n",
    "        self.embed = Embed()\n",
    "        self.dense1 = FC(filters_dense1)\n",
    "\n",
    "    def call(self, input_features):\n",
    "        activation = self.convolution(input_features)\n",
    "        activation1 = self.dense(activation)\n",
    "        #print(activation.shape)\n",
    "        activation1 = self.embed(activation1)\n",
    "        activation1 = tf.expand_dims(activation1, axis=3)\n",
    "        #print(activation.shape, activation1.shape)\n",
    "        activation2 = tf.concat([activation, activation1], 3)#do something that puts the conv and the embedding together\n",
    "        activation2 = self.dense1(activation2)\n",
    "        #print(activation2.shape)\n",
    "        return activation2\n",
    "\n",
    "class PartialModel(tf.keras.Model):\n",
    "    def __init__(self, filters_conv=[64,128], filters_dense=[2000,500,15]):\n",
    "        super(PartialModel, self).__init__()\n",
    "        self.convolution = Convolution(filters_conv)\n",
    "        self.dense = FC(filters_dense)\n",
    "\n",
    "\n",
    "    def call(self, input_features):\n",
    "        activation = self.convolution(input_features)\n",
    "        activation1 = self.dense(activation)\n",
    "        #print(activation.shape, activation1.shape)\n",
    "        return activation1\n",
    "\n",
    "model = FullModel()\n",
    "\n",
    "partial_model = PartialModel()\n",
    "\n",
    "model.build(input_shape=(32, 224, 224, 3))\n",
    "partial_model.build(input_shape=(32, 224, 224, 3))\n",
    "print(model.summary(), partial_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(partial_model, model, x_train, y_train, _y_train):\n",
    "    loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    loss_binary = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    intermidiate_loss = loss_binary(partial_model(x_train), y_train)\n",
    "    #print(intermidiate_loss)\n",
    "    reconstruction_error = loss_object(model(x_train), _y_train)\n",
    "    return (reconstruction_error + intermidiate_loss)/2\n",
    "\n",
    "\n",
    "def train(loss, partial_model, model, opt, x_train=None, y_train=None, _y_train=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        gradients = tape.gradient(loss(partial_model, model, x_train, y_train, _y_train), model.trainable_variables)\n",
    "        gradient_variables = zip(gradients, model.trainable_variables)\n",
    "        opt.apply_gradients(gradient_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = list(df['filenames'][:18000])\n",
    "train_y = list(df['labels'][:18000])\n",
    "train_y_ = list(df['labels2'][:18000])\n",
    "val_x = list(df['filenames'][18000:21000])\n",
    "val_y = list(df['labels'][18000:21000])\n",
    "val_y_ = list(df['labels2'][18000:21000])\n",
    "test_x = list(df['filenames'][21000:])\n",
    "test_y = list(df['labels'][21000:])\n",
    "test_y_ = list(df['labels2'][21000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = create_dataset(train_x, train_y, train_y_)\n",
    "val_generator = create_dataset(val_x, val_y, val_y_)\n",
    "test_generator = create_dataset(test_x, test_y, test_y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "opt = tf.keras.optimizers.Adam() #learning_rate=learning_rate: will add in future version\n",
    "num_epochs = 20\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for batch in range(len(train_x)//56):\n",
    "        features, labels1, labels2 = next(iter(train_generator))\n",
    "        #print(features, labels1, labels2)\n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        epoch_accuracy = tf.keras.metrics.Accuracy()\n",
    "        partial_model = PartialModel()\n",
    "        model = FullModel()\n",
    "        train(loss, partial_model, model, opt, x_train=features, y_train=labels1, _y_train=labels2)\n",
    "        loss_values = loss(partial_model, model, x_train=features, y_train=labels1, _y_train=labels2)\n",
    "        print(tf.summary.scalar('loss', loss_values))\n",
    "        # End epoch\n",
    "        train_loss_results.append(loss_values)\n",
    "        train_accuracy_results.append(epoch_accuracy(labels2, model(features, training=True)))\n",
    "\n",
    "    if i % 2 == 0:\n",
    "        print(i, epoch_loss_avg.result(), epoch_accuracy.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
