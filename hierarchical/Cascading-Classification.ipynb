{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascading Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import IPython.display as display\n",
    "\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import random\n",
    "#importing module\n",
    "import sys\n",
    "sys.path.insert(0, '../data')\n",
    "from datahandler_multilabel import create_dataset\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24999 24999\n"
     ]
    }
   ],
   "source": [
    "with open('../data/filenames.pkl', 'rb') as infile:\n",
    "    filenames = pickle.load(infile)\n",
    "\n",
    "with open('../data/labels.pkl', 'rb') as infile2:\n",
    "    labels = pickle.load(infile2)\n",
    "    \n",
    "print(len(filenames), len(labels))\n",
    "df = pd.concat([pd.Series(filenames, name='filenames'), pd.Series(labels, name='labels')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24998 24998\n"
     ]
    }
   ],
   "source": [
    "with open('../data/filenames_level2.pkl', 'rb') as infile:\n",
    "    filenames2 = pickle.load(infile)\n",
    "\n",
    "with open('../data/labels_level2.pkl', 'rb') as infile2:\n",
    "    labels2 = pickle.load(infile2)\n",
    "\n",
    "print(len(filenames2), len(labels2))\n",
    "df2 = pd.concat([pd.Series(filenames2, name='filenames'), pd.Series(labels2, name='labels2')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df2, on='filenames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data_tate\\A00001_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data_tate\\A00002_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\data_tate\\A00003_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\data_tate\\A00004_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\data_tate\\A00005_8.jpg</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>..\\..\\data_tate\\T13856_8.jpg</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>..\\..\\data_tate\\T13858_8.jpg</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>..\\..\\data_tate\\T13863_8.jpg</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>..\\..\\data_tate\\T13864_8.jpg</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>..\\..\\data_tate\\T13869_8.jpg</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24998 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filenames  \\\n",
       "0      ..\\..\\data_tate\\A00001_8.jpg   \n",
       "1      ..\\..\\data_tate\\A00002_8.jpg   \n",
       "2      ..\\..\\data_tate\\A00003_8.jpg   \n",
       "3      ..\\..\\data_tate\\A00004_8.jpg   \n",
       "4      ..\\..\\data_tate\\A00005_8.jpg   \n",
       "...                             ...   \n",
       "24993  ..\\..\\data_tate\\T13856_8.jpg   \n",
       "24994  ..\\..\\data_tate\\T13858_8.jpg   \n",
       "24995  ..\\..\\data_tate\\T13863_8.jpg   \n",
       "24996  ..\\..\\data_tate\\T13864_8.jpg   \n",
       "24997  ..\\..\\data_tate\\T13869_8.jpg   \n",
       "\n",
       "                                                  labels  \\\n",
       "0      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4      [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, ...   \n",
       "...                                                  ...   \n",
       "24993  [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "24994  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "24995  [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24996  [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24997  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 labels2  \n",
       "0      [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1      [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2      [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3      [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4      [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
       "...                                                  ...  \n",
       "24993  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24994  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24995  [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24997  [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "\n",
       "[24998 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 112, 112, 64)\n",
      "(32, 56, 56, 32)\n",
      "(32, 28, 28, 32)\n",
      "(32, 28, 28, 32)\n",
      "(32, 15)\n",
      "(32,)\n",
      "(32, 784)\n",
      "(32, 28, 28, 32) (32, 28, 28, 1)\n",
      "Model: \"full_model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "convolution_16 (Convolution) multiple                  30016     \n",
      "_________________________________________________________________\n",
      "fc_32 (FC)                   multiple                  12673515  \n",
      "_________________________________________________________________\n",
      "embed_16 (Embed)             multiple                  11760     \n",
      "_________________________________________________________________\n",
      "fc_33 (FC)                   multiple                  13097141  \n",
      "=================================================================\n",
      "Total params: 25,812,432\n",
      "Trainable params: 25,812,176\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class Convolution(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, shape=(224,224,3), kernel_size=3,\n",
    "                 pool_size=(2,2), activation='relu', padding='same'):\n",
    "        super(Convolution, self).__init__()\n",
    "        self.input_layer = tf.keras.layers.InputLayer(\n",
    "            input_shape = shape,\n",
    "        )\n",
    "        self.conv_layer = tf.keras.layers.Conv2D(\n",
    "            filters = filters[0], \n",
    "            padding = padding,\n",
    "            kernel_size = kernel_size,\n",
    "            activation = activation,\n",
    "            )\n",
    "        self.conv_layer1 = tf.keras.layers.Conv2D(\n",
    "            filters = filters[1],\n",
    "            padding = padding,\n",
    "            kernel_size = kernel_size,\n",
    "            activation = activation,\n",
    "            )\n",
    "        self.conv_layer2 = tf.keras.layers.Conv2D(\n",
    "            filters = filters[1],\n",
    "            padding = padding,\n",
    "            kernel_size = kernel_size,\n",
    "            activation = activation,\n",
    "            )\n",
    "        self.nn_pooling = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size = pool_size,\n",
    "            padding = padding,\n",
    "            strides = (2,2)\n",
    "            )\n",
    "        self.nn_dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.nn_batchnorm = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "        self.nn_batchnorm1 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "        self.nn_batchnorm2 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        activation = self.input_layer(input_features)\n",
    "        activation = self.conv_layer(activation)\n",
    "        activation = self.nn_batchnorm(activation)\n",
    "        activation = self.nn_pooling(activation)\n",
    "        print(activation.shape)\n",
    "        activation = self.conv_layer1(activation)\n",
    "        activation = self.nn_batchnorm1(activation)\n",
    "        activation = self.nn_pooling(activation)\n",
    "        print(activation.shape)\n",
    "        activation = self.conv_layer2(activation)\n",
    "        activation = self.nn_batchnorm2(activation)\n",
    "        activation = self.nn_pooling(activation)\n",
    "        print(activation.shape)\n",
    "        return activation\n",
    "\n",
    "\n",
    "class FC(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(FC, self).__init__()\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.dense = tf.keras.layers.Dense(filters[0], activation='relu')\n",
    "        self.dense1 = tf.keras.layers.Dense(filters[1], activation='relu')\n",
    "        self.out = tf.keras.layers.Dense(filters[2], activation='softmax')\n",
    "\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        activation = self.flat(input_features)\n",
    "        activation = self.dense(activation)\n",
    "        activation = self.dense1(activation)\n",
    "        activation = self.out(activation)\n",
    "        return activation\n",
    "    \n",
    "    \n",
    "class Embed(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Embed, self).__init__()\n",
    "        self.embed = tf.keras.layers.Embedding(15, 28*28, input_length=1)\n",
    "        self.reshape = tf.keras.layers.Reshape((28,28))\n",
    "        \n",
    "        \n",
    "    def call(self, input_features):\n",
    "        print(input_features.shape)\n",
    "        activation = tf.argmax(input_features, axis=1)\n",
    "        print(activation.shape)\n",
    "        activation = self.embed(activation)\n",
    "        print(activation.shape)\n",
    "        activation = self.reshape(activation)\n",
    "        return activation\n",
    "    \n",
    "\n",
    "class FullModel(tf.keras.Model):\n",
    "    def __init__(self, filters_conv=[64,32], filters_dense=[500,250,15], filters_dense1=[500,250,141]):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.convolution = Convolution(filters_conv)\n",
    "        self.dense = FC(filters_dense)\n",
    "        self.embed = Embed()\n",
    "        self.dense1 = FC(filters_dense1)\n",
    "\n",
    "    def call(self, input_features):\n",
    "        activation = self.convolution(input_features)\n",
    "        activation1 = self.dense(activation)\n",
    "        print(activation.shape)\n",
    "        activation1 = self.embed(activation1)\n",
    "        activation1 = tf.expand_dims(activation1, axis=3)\n",
    "        print(activation.shape, activation1.shape)\n",
    "        #print(activation1)\n",
    "        activation2 = tf.concat([activation, activation1], 3)#do something that puts the conv and the embedding together\n",
    "        activation2 = self.dense1(activation2)\n",
    "        return activation2\n",
    "\n",
    "model = FullModel()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.build(input_shape=(32, 224, 224, 3))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(partial_model, model, x_train, y_train):\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    loss_binary = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    intermidiate_loss = loss_binary(partial_model(x_train), y_train)\n",
    "    #print(intermidiate_loss)\n",
    "    reconstruction_error = loss_object(model(x_train), y_train)\n",
    "    return (reconstruction_error + intermidiate_loss)/2\n",
    "\n",
    "\n",
    "def train(loss, partial_model, model, opt, x_train=None, y_train=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        gradients = tape.gradient(loss(partial_model, model, x_train, y_train), model.trainable_variables)\n",
    "        gradient_variables = zip(gradients, model.trainable_variables)\n",
    "        opt.apply_gradients(gradient_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = list(df['filenames'][:18000])\n",
    "train_y = list(df['labels'][:18000])\n",
    "train_y_ = list(df['labels2'][:18000])\n",
    "val_x = list(df['filenames'][18000:21000])\n",
    "val_y = list(df['labels'][18000:21000])\n",
    "val_y_ = list(df['labels2'][18000:21000])\n",
    "test_x = list(df['filenames'][21000:])\n",
    "test_y = list(df['labels'][21000:])\n",
    "test_y_ = list(df['labels2'][21000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer conv2d_39 expects 1 inputs, but it received 32 input tensors. Inputs received: ['..\\\\..\\\\data_tate\\\\A00001_8.jpg', '..\\\\..\\\\data_tate\\\\A00002_8.jpg', '..\\\\..\\\\data_tate\\\\A00003_8.jpg', '..\\\\..\\\\data_tate\\\\A00004_8.jpg', '..\\\\..\\\\data_tate\\\\A00005_8.jpg', '..\\\\..\\\\data_tate\\\\A00006_8.jpg', '..\\\\..\\\\data_tate\\\\A00007_8.jpg', '..\\\\..\\\\data_tate\\\\A00008_8.jpg', '..\\\\..\\\\data_tate\\\\A00009_8.jpg', '..\\\\..\\\\data_tate\\\\A00010_8.jpg', '..\\\\..\\\\data_tate\\\\A00011_8.jpg', '..\\\\..\\\\data_tate\\\\A00012_8.jpg', '..\\\\..\\\\data_tate\\\\A00013_8.jpg', '..\\\\..\\\\data_tate\\\\A00014_8.jpg', '..\\\\..\\\\data_tate\\\\A00015_8.jpg', '..\\\\..\\\\data_tate\\\\A00016_8.jpg', '..\\\\..\\\\data_tate\\\\A00017_8.jpg', '..\\\\..\\\\data_tate\\\\A00018_8.jpg', '..\\\\..\\\\data_tate\\\\A00019_8.jpg', '..\\\\..\\\\data_tate\\\\A00020_8.jpg', '..\\\\..\\\\data_tate\\\\A00021_8.jpg', '..\\\\..\\\\data_tate\\\\A00022_8.jpg', '..\\\\..\\\\data_tate\\\\A00023_8.jpg', '..\\\\..\\\\data_tate\\\\A00024_8.jpg', '..\\\\..\\\\data_tate\\\\A00025_8.jpg', '..\\\\..\\\\data_tate\\\\A00026_8.jpg', '..\\\\..\\\\data_tate\\\\A00027_8.jpg', '..\\\\..\\\\data_tate\\\\A00028_8.jpg', '..\\\\..\\\\data_tate\\\\A00029_8.jpg', '..\\\\..\\\\data_tate\\\\A00031_8.jpg', '..\\\\..\\\\data_tate\\\\A00032_8.jpg', '..\\\\..\\\\data_tate\\\\A00033_8.jpg']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-39375196beb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     ])\n\u001b[0;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFullModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartial_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mloss_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartial_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-aec025082107>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(loss, partial_model, model, opt, x_train, y_train)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartial_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartial_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mgradient_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-aec025082107>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(partial_model, model, x_train, y_train)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mloss_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mloss_binary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mintermidiate_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_binary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartial_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#print(intermidiate_loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mreconstruction_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[1;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-8f18b506a9de>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_batchnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_pooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    885\u001b[0m         \u001b[1;31m# Eager execution on data tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 887\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    888\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2120\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2121\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[1;32m-> 2122\u001b[1;33m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[0;32m   2123\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2124\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    153\u001b[0m                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' inputs, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m                      \u001b[1;34m'but it received '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                      ' input tensors. Inputs received: ' + str(inputs))\n\u001b[0m\u001b[0;32m    156\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0minput_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer conv2d_39 expects 1 inputs, but it received 32 input tensors. Inputs received: ['..\\\\..\\\\data_tate\\\\A00001_8.jpg', '..\\\\..\\\\data_tate\\\\A00002_8.jpg', '..\\\\..\\\\data_tate\\\\A00003_8.jpg', '..\\\\..\\\\data_tate\\\\A00004_8.jpg', '..\\\\..\\\\data_tate\\\\A00005_8.jpg', '..\\\\..\\\\data_tate\\\\A00006_8.jpg', '..\\\\..\\\\data_tate\\\\A00007_8.jpg', '..\\\\..\\\\data_tate\\\\A00008_8.jpg', '..\\\\..\\\\data_tate\\\\A00009_8.jpg', '..\\\\..\\\\data_tate\\\\A00010_8.jpg', '..\\\\..\\\\data_tate\\\\A00011_8.jpg', '..\\\\..\\\\data_tate\\\\A00012_8.jpg', '..\\\\..\\\\data_tate\\\\A00013_8.jpg', '..\\\\..\\\\data_tate\\\\A00014_8.jpg', '..\\\\..\\\\data_tate\\\\A00015_8.jpg', '..\\\\..\\\\data_tate\\\\A00016_8.jpg', '..\\\\..\\\\data_tate\\\\A00017_8.jpg', '..\\\\..\\\\data_tate\\\\A00018_8.jpg', '..\\\\..\\\\data_tate\\\\A00019_8.jpg', '..\\\\..\\\\data_tate\\\\A00020_8.jpg', '..\\\\..\\\\data_tate\\\\A00021_8.jpg', '..\\\\..\\\\data_tate\\\\A00022_8.jpg', '..\\\\..\\\\data_tate\\\\A00023_8.jpg', '..\\\\..\\\\data_tate\\\\A00024_8.jpg', '..\\\\..\\\\data_tate\\\\A00025_8.jpg', '..\\\\..\\\\data_tate\\\\A00026_8.jpg', '..\\\\..\\\\data_tate\\\\A00027_8.jpg', '..\\\\..\\\\data_tate\\\\A00028_8.jpg', '..\\\\..\\\\data_tate\\\\A00029_8.jpg', '..\\\\..\\\\data_tate\\\\A00031_8.jpg', '..\\\\..\\\\data_tate\\\\A00032_8.jpg', '..\\\\..\\\\data_tate\\\\A00033_8.jpg']"
     ]
    }
   ],
   "source": [
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "opt = tf.keras.optimizers.Adam() #learning_rate=learning_rate: will add in future version\n",
    "num_epochs = 20\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    x_train = train_x[i:i+32]\n",
    "    y_train = train_y[i:i+32]\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    partial_model = keras.models.Sequential([\n",
    "        Convolution([64, 64]),\n",
    "        FC([400,50,15]),\n",
    "    ])\n",
    "    model = FullModel()\n",
    "    train(loss, partial_model, model, opt, x_train=x_train, y_train=y_train)\n",
    "    loss_values = loss(partial_model, model, x_train=x_train, y_train=y_train)\n",
    "    print(tf.summary.scalar('loss', loss_values))\n",
    "    # End epoch\n",
    "    train_loss_results.append(loss_values)\n",
    "    train_accuracy_results.append(epoch_accuracy(train_labels, output(train_images, training=True)))\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(epoch, epoch_loss_avg.result(), epoch_accuracy.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
