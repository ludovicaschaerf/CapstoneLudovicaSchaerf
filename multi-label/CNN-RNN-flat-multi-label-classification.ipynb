{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-RNN multi-label classification\n",
    "\n",
    "This notebook contains the preprocessing that was necessary to use the CNN-RNN classification repository \n",
    "(https://github.com/AmrMaghraby/CNN-RNN-A-Unified-Framework-for-Multi-label-Image-Classification)\n",
    "\n",
    "Furthermore, it contains the command line to use from terminal to run the downloaded code, in conjuction with the data_loader.py that was written to work specifically with my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MyData.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24999\n"
     ]
    }
   ],
   "source": [
    "with open('../data/filenames.pkl', 'rb') as infile:\n",
    "    filenames = pickle.load(infile)\n",
    "    \n",
    "with open('../data/labels.pkl', 'rb') as infile2:\n",
    "    labels = pickle.load(infile2)\n",
    "    \n",
    "df = pd.concat([pd.Series(filenames, name='filenames'), pd.Series(labels, name='labels')], axis=1)\n",
    "\n",
    "labels_dict = {0:'people',1:'objects',2:'places',3:'architecture',4:'abstraction',5:'society',\\\n",
    "          6:'nature',7:'emotions, concepts and ideas',8:'interiors',9:'work and occupations', \\\n",
    "          10:'symbols & personifications',11:'religion and belief',12:'leisure and pastimes',\\\n",
    "          13:'history',14:'literature and fiction',15:'group/movement'}\n",
    "\n",
    "labels_names = [[]]*len(df.labels)\n",
    "for k in range(len(df.labels)):\n",
    "    labels_names[k] = []\n",
    "    for i in range(len(df.labels[k])):\n",
    "        if df.labels[k][i] == 1:\n",
    "            labels_names[k].append(labels_dict[i])\n",
    "\n",
    "print(len(labels_names))\n",
    "out = [(filenames[i].split('\\\\')[-1], labels_names[i]) for i in range(len(labels_names))]\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "with open('../data/results/myData.json', 'w') as outF:\n",
    "    aux = {}\n",
    "    for line in out:\n",
    "        if \"group/movement\" in line[1]:\n",
    "            continue\n",
    "        aux[line[0]] = line[1]\n",
    "    json.dump(aux, outF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idx2path.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "A00001_8.jpg ['people', 'religion and belief']\n",
      "0 A00001_8.jpg\n"
     ]
    }
   ],
   "source": [
    "d = json.load(open(\"../data/results/MyData.json\"))\n",
    "words = {}\n",
    "for k in d.keys():\n",
    "    for word in d[k]:\n",
    "        if word not in words.keys():\n",
    "            words[word] = 0\n",
    "        words[word] += 1\n",
    "print(len(words.keys()))\n",
    "\n",
    "for k in d.keys():\n",
    "    print(k, d[k])\n",
    "    break\n",
    "    \n",
    "idx2path = {}\n",
    "\n",
    "for i, k in enumerate(d.keys()):\n",
    "    idx2path[str(i)] = k\n",
    "\n",
    "for k in idx2path.keys():\n",
    "    print(k, idx2path[k])\n",
    "    break\n",
    "    \n",
    "json.dump(idx2path, open(\"../data/results/idx2path.json\", 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zh_vocab.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "for word in words.keys():\n",
    "    print(word, words[word])\n",
    "    lista.append(word)\n",
    "print(lista)\n",
    "json.dump(lista, open(\"../data/results/MyWords.json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab dict_keys(['<pad>', '<start>', '<end>', '<unk>', 'people', 'religion and belief', 'emotions, concepts and ideas', 'work and occupations', 'society', 'nature', 'literature and fiction', 'objects', 'places', 'architecture', 'symbols & personifications', 'leisure and pastimes', 'interiors', 'abstraction', 'history'])\n",
      "Total vocabulary size: 19\n",
      "Saved the vocabulary wrapper to '../data/results/zh_vocab.pkl'\n"
     ]
    }
   ],
   "source": [
    "! python CNN_RNN/build_vocab.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the code from terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python CNN_RNN/train.py --vocab_path ../data/zh_vocab.pkl --caption_path ../data/MyData.json --image_dir ../../data_tate --idx2path_path ../data/idx2path.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
