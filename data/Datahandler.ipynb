{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://towardsdatascience.com/multi-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ludovica\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (9,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>accession_number</th>\n",
       "      <th>artist</th>\n",
       "      <th>artistRole</th>\n",
       "      <th>artistId</th>\n",
       "      <th>title</th>\n",
       "      <th>dateText</th>\n",
       "      <th>medium</th>\n",
       "      <th>creditLine</th>\n",
       "      <th>year</th>\n",
       "      <th>acquisitionYear</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>depth</th>\n",
       "      <th>units</th>\n",
       "      <th>inscription</th>\n",
       "      <th>thumbnailCopyright</th>\n",
       "      <th>thumbnailUrl</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1035</td>\n",
       "      <td>A00001</td>\n",
       "      <td>Blake, Robert</td>\n",
       "      <td>artist</td>\n",
       "      <td>38</td>\n",
       "      <td>A Figure Bowing before a Seated Old Man with h...</td>\n",
       "      <td>date not known</td>\n",
       "      <td>Watercolour, ink, chalk and graphite on paper....</td>\n",
       "      <td>Presented by Mrs John Richmond 1922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>support: 394 x 419 mm</td>\n",
       "      <td>394</td>\n",
       "      <td>419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.tate.org.uk/art/images/work/A/A00/A...</td>\n",
       "      <td>http://www.tate.org.uk/art/artworks/blake-a-fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1036</td>\n",
       "      <td>A00002</td>\n",
       "      <td>Blake, Robert</td>\n",
       "      <td>artist</td>\n",
       "      <td>38</td>\n",
       "      <td>Two Drawings of Frightened Figures, Probably f...</td>\n",
       "      <td>date not known</td>\n",
       "      <td>Graphite on paper</td>\n",
       "      <td>Presented by Mrs John Richmond 1922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>support: 311 x 213 mm</td>\n",
       "      <td>311</td>\n",
       "      <td>213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.tate.org.uk/art/images/work/A/A00/A...</td>\n",
       "      <td>http://www.tate.org.uk/art/artworks/blake-two-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1037</td>\n",
       "      <td>A00003</td>\n",
       "      <td>Blake, Robert</td>\n",
       "      <td>artist</td>\n",
       "      <td>38</td>\n",
       "      <td>The Preaching of Warning. Verso: An Old Man En...</td>\n",
       "      <td>?c.1785</td>\n",
       "      <td>Graphite on paper. Verso: graphite on paper</td>\n",
       "      <td>Presented by Mrs John Richmond 1922</td>\n",
       "      <td>1785</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>support: 343 x 467 mm</td>\n",
       "      <td>343</td>\n",
       "      <td>467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.tate.org.uk/art/images/work/A/A00/A...</td>\n",
       "      <td>http://www.tate.org.uk/art/artworks/blake-the-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1038</td>\n",
       "      <td>A00004</td>\n",
       "      <td>Blake, Robert</td>\n",
       "      <td>artist</td>\n",
       "      <td>38</td>\n",
       "      <td>Six Drawings of Figures with Outstretched Arms</td>\n",
       "      <td>date not known</td>\n",
       "      <td>Graphite on paper</td>\n",
       "      <td>Presented by Mrs John Richmond 1922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>support: 318 x 394 mm</td>\n",
       "      <td>318</td>\n",
       "      <td>394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.tate.org.uk/art/images/work/A/A00/A...</td>\n",
       "      <td>http://www.tate.org.uk/art/artworks/blake-six-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1039</td>\n",
       "      <td>A00005</td>\n",
       "      <td>Blake, William</td>\n",
       "      <td>artist</td>\n",
       "      <td>39</td>\n",
       "      <td>The Circle of the Lustful: Francesca da Rimini...</td>\n",
       "      <td>1826â€“7, reprinted 1892</td>\n",
       "      <td>Line engraving on paper</td>\n",
       "      <td>Purchased with the assistance of a special gra...</td>\n",
       "      <td>1826</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>image: 243 x 335 mm</td>\n",
       "      <td>243</td>\n",
       "      <td>335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.tate.org.uk/art/images/work/A/A00/A...</td>\n",
       "      <td>http://www.tate.org.uk/art/artworks/blake-the-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69196</th>\n",
       "      <td>122960</td>\n",
       "      <td>T13865</td>\n",
       "      <td>P-Orridge, Genesis</td>\n",
       "      <td>artist</td>\n",
       "      <td>16646</td>\n",
       "      <td>Larvae (from Tampax Romana)</td>\n",
       "      <td>1975</td>\n",
       "      <td>Perspex, Wood, hairpiece, tampon and human blood</td>\n",
       "      <td>Transferred from Tate Archive 2012</td>\n",
       "      <td>1975</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>object: 305 x 305 x 135 mm</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>135.0</td>\n",
       "      <td>mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.tate.org.uk/art/artworks/p-orridge-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69197</th>\n",
       "      <td>122961</td>\n",
       "      <td>T13866</td>\n",
       "      <td>P-Orridge, Genesis</td>\n",
       "      <td>artist</td>\n",
       "      <td>16646</td>\n",
       "      <td>Living Womb (from Tampax Romana)</td>\n",
       "      <td>1976</td>\n",
       "      <td>Wood, Perspex, plastic, photograph on paper, t...</td>\n",
       "      <td>Transferred from Tate Archive 2012</td>\n",
       "      <td>1976</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>object: 305 x 305 x 135 mm</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>135.0</td>\n",
       "      <td>mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.tate.org.uk/art/artworks/p-orridge-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69198</th>\n",
       "      <td>121181</td>\n",
       "      <td>T13867</td>\n",
       "      <td>Hatoum, Mona</td>\n",
       "      <td>artist</td>\n",
       "      <td>2365</td>\n",
       "      <td>Present Tense</td>\n",
       "      <td>1996</td>\n",
       "      <td>Soap and glass beads</td>\n",
       "      <td>Presented by Tate Members 2013</td>\n",
       "      <td>1996</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>displayed: 45 x 2410 x 2990 mm</td>\n",
       "      <td>45</td>\n",
       "      <td>2410</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.tate.org.uk/art/artworks/hatoum-pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69199</th>\n",
       "      <td>112306</td>\n",
       "      <td>T13868</td>\n",
       "      <td>Creed, Martin</td>\n",
       "      <td>artist</td>\n",
       "      <td>2760</td>\n",
       "      <td>Work No. 227: The lights going on and off</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gallery lighting</td>\n",
       "      <td>Purchased with funds provided by Tate Members,...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Overall display dimensions variable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.tate.org.uk/art/artworks/creed-work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69200</th>\n",
       "      <td>127035</td>\n",
       "      <td>T13869</td>\n",
       "      <td>Brunias, Agostino</td>\n",
       "      <td>artist</td>\n",
       "      <td>3824</td>\n",
       "      <td>Dancing Scene in the West Indies</td>\n",
       "      <td>1764â€“96</td>\n",
       "      <td>Oil paint on canvas</td>\n",
       "      <td>Purchased with assistance from Tate Patrons an...</td>\n",
       "      <td>1764</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>unconfirmed: 508 x 660 mm</td>\n",
       "      <td>508</td>\n",
       "      <td>660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.tate.org.uk/art/images/work/T/T13/T...</td>\n",
       "      <td>http://www.tate.org.uk/art/artworks/brunias-da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69201 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id accession_number              artist artistRole  artistId  \\\n",
       "0        1035           A00001       Blake, Robert     artist        38   \n",
       "1        1036           A00002       Blake, Robert     artist        38   \n",
       "2        1037           A00003       Blake, Robert     artist        38   \n",
       "3        1038           A00004       Blake, Robert     artist        38   \n",
       "4        1039           A00005      Blake, William     artist        39   \n",
       "...       ...              ...                 ...        ...       ...   \n",
       "69196  122960           T13865  P-Orridge, Genesis     artist     16646   \n",
       "69197  122961           T13866  P-Orridge, Genesis     artist     16646   \n",
       "69198  121181           T13867        Hatoum, Mona     artist      2365   \n",
       "69199  112306           T13868       Creed, Martin     artist      2760   \n",
       "69200  127035           T13869   Brunias, Agostino     artist      3824   \n",
       "\n",
       "                                                   title  \\\n",
       "0      A Figure Bowing before a Seated Old Man with h...   \n",
       "1      Two Drawings of Frightened Figures, Probably f...   \n",
       "2      The Preaching of Warning. Verso: An Old Man En...   \n",
       "3         Six Drawings of Figures with Outstretched Arms   \n",
       "4      The Circle of the Lustful: Francesca da Rimini...   \n",
       "...                                                  ...   \n",
       "69196                        Larvae (from Tampax Romana)   \n",
       "69197                   Living Womb (from Tampax Romana)   \n",
       "69198                                      Present Tense   \n",
       "69199          Work No. 227: The lights going on and off   \n",
       "69200                   Dancing Scene in the West Indies   \n",
       "\n",
       "                     dateText  \\\n",
       "0              date not known   \n",
       "1              date not known   \n",
       "2                     ?c.1785   \n",
       "3              date not known   \n",
       "4      1826â€“7, reprinted 1892   \n",
       "...                       ...   \n",
       "69196                    1975   \n",
       "69197                    1976   \n",
       "69198                    1996   \n",
       "69199                    2000   \n",
       "69200                 1764â€“96   \n",
       "\n",
       "                                                  medium  \\\n",
       "0      Watercolour, ink, chalk and graphite on paper....   \n",
       "1                                      Graphite on paper   \n",
       "2            Graphite on paper. Verso: graphite on paper   \n",
       "3                                      Graphite on paper   \n",
       "4                                Line engraving on paper   \n",
       "...                                                  ...   \n",
       "69196   Perspex, Wood, hairpiece, tampon and human blood   \n",
       "69197  Wood, Perspex, plastic, photograph on paper, t...   \n",
       "69198                               Soap and glass beads   \n",
       "69199                                   Gallery lighting   \n",
       "69200                                Oil paint on canvas   \n",
       "\n",
       "                                              creditLine  year  \\\n",
       "0                    Presented by Mrs John Richmond 1922   NaN   \n",
       "1                    Presented by Mrs John Richmond 1922   NaN   \n",
       "2                    Presented by Mrs John Richmond 1922  1785   \n",
       "3                    Presented by Mrs John Richmond 1922   NaN   \n",
       "4      Purchased with the assistance of a special gra...  1826   \n",
       "...                                                  ...   ...   \n",
       "69196                 Transferred from Tate Archive 2012  1975   \n",
       "69197                 Transferred from Tate Archive 2012  1976   \n",
       "69198                     Presented by Tate Members 2013  1996   \n",
       "69199  Purchased with funds provided by Tate Members,...  2000   \n",
       "69200  Purchased with assistance from Tate Patrons an...  1764   \n",
       "\n",
       "       acquisitionYear                           dimensions width height  \\\n",
       "0               1922.0                support: 394 x 419 mm   394    419   \n",
       "1               1922.0                support: 311 x 213 mm   311    213   \n",
       "2               1922.0                support: 343 x 467 mm   343    467   \n",
       "3               1922.0                support: 318 x 394 mm   318    394   \n",
       "4               1919.0                  image: 243 x 335 mm   243    335   \n",
       "...                ...                                  ...   ...    ...   \n",
       "69196           2013.0           object: 305 x 305 x 135 mm   305    305   \n",
       "69197           2013.0           object: 305 x 305 x 135 mm   305    305   \n",
       "69198           2013.0       displayed: 45 x 2410 x 2990 mm    45   2410   \n",
       "69199           2013.0  Overall display dimensions variable   NaN    NaN   \n",
       "69200           2013.0            unconfirmed: 508 x 660 mm   508    660   \n",
       "\n",
       "        depth units inscription thumbnailCopyright  \\\n",
       "0         NaN    mm         NaN                NaN   \n",
       "1         NaN    mm         NaN                NaN   \n",
       "2         NaN    mm         NaN                NaN   \n",
       "3         NaN    mm         NaN                NaN   \n",
       "4         NaN    mm         NaN                NaN   \n",
       "...       ...   ...         ...                ...   \n",
       "69196   135.0    mm         NaN                NaN   \n",
       "69197   135.0    mm         NaN                NaN   \n",
       "69198  2990.0    mm         NaN                NaN   \n",
       "69199     NaN   NaN         NaN                NaN   \n",
       "69200     NaN    mm         NaN                NaN   \n",
       "\n",
       "                                            thumbnailUrl  \\\n",
       "0      http://www.tate.org.uk/art/images/work/A/A00/A...   \n",
       "1      http://www.tate.org.uk/art/images/work/A/A00/A...   \n",
       "2      http://www.tate.org.uk/art/images/work/A/A00/A...   \n",
       "3      http://www.tate.org.uk/art/images/work/A/A00/A...   \n",
       "4      http://www.tate.org.uk/art/images/work/A/A00/A...   \n",
       "...                                                  ...   \n",
       "69196                                                NaN   \n",
       "69197                                                NaN   \n",
       "69198                                                NaN   \n",
       "69199                                                NaN   \n",
       "69200  http://www.tate.org.uk/art/images/work/T/T13/T...   \n",
       "\n",
       "                                                     url  \n",
       "0      http://www.tate.org.uk/art/artworks/blake-a-fi...  \n",
       "1      http://www.tate.org.uk/art/artworks/blake-two-...  \n",
       "2      http://www.tate.org.uk/art/artworks/blake-the-...  \n",
       "3      http://www.tate.org.uk/art/artworks/blake-six-...  \n",
       "4      http://www.tate.org.uk/art/artworks/blake-the-...  \n",
       "...                                                  ...  \n",
       "69196  http://www.tate.org.uk/art/artworks/p-orridge-...  \n",
       "69197  http://www.tate.org.uk/art/artworks/p-orridge-...  \n",
       "69198  http://www.tate.org.uk/art/artworks/hatoum-pre...  \n",
       "69199  http://www.tate.org.uk/art/artworks/creed-work...  \n",
       "69200  http://www.tate.org.uk/art/artworks/brunias-da...  \n",
       "\n",
       "[69201 rows x 20 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info = pd.read_csv(os.path.join(\"D:\", \"collection\", \"artwork_data.csv\"))\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('TateDictLevel1.json', 'r') as infile:\n",
    "    tree1 = json.load(infile)\n",
    "len(tree1.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15469"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tree1['people'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get a list of keys from dictionary which has the given value\n",
    "'''\n",
    "def getKeysByValue(dictOfElements, valueToFind):\n",
    "    listOfKeys = list()\n",
    "    listOfItems = list()\n",
    "    for item in dictOfElements.items():\n",
    "        listOfItems.append(item)\n",
    "    for item in listOfItems:\n",
    "        if valueToFind in item[1]:\n",
    "            listOfKeys.append((valueToFind, item[0]))\n",
    "    \n",
    "    return listOfKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69201\n"
     ]
    }
   ],
   "source": [
    "values = data_info.accession_number.tolist()\n",
    "tuples = list()\n",
    "\n",
    "for i in range(len(values)):\n",
    "    tuples.append(getKeysByValue(tree1, values[i]))\n",
    "    \n",
    "    \n",
    "print(len(tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2num = {'people':0, 'objects':1, 'places':2, 'architecture':3, 'abstraction':4, 'society':5, 'nature':6, \\\n",
    "             'emotions, concepts and ideas':7, 'interiors':8, 'work and occupations':9, 'symbols & personifications':10, \\\n",
    "             'religion and belief':11, 'leisure and pastimes':12, 'history':13, 'literature and fiction':14, 'group/movement':15}\n",
    "class2num['architecture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26968"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "img_target = []\n",
    "\n",
    "for tupl in tuples:\n",
    "    if len(tupl) > 0:\n",
    "        zarray = numpy.zeros(16)\n",
    "        for i in range(len(tupl)):\n",
    "            zarray[class2num[tupl[i][1]]] = 1\n",
    "        img_target.append((tupl[0][0], zarray))\n",
    "        \n",
    "len(img_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224 # Specify height and width of image to match the input format of the model\n",
    "CHANNELS = 3 # Keep RGB color channels to match the input format of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(filename, label):\n",
    "    \"\"\"Function that returns a tuple of normalized image array and labels array.\n",
    "    Args:\n",
    "        filename: string representing path to image\n",
    "        label: 0/1 one-dimensional array of size N_LABELS\n",
    "    \"\"\"\n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    print(image_decoded)\n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    # Decode it into a dense vector\n",
    "    return image_normalized, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256 # Big enough to measure an F1-score\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically to reduce GPU and CPU idle time\n",
    "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_dataset(filenames, labels, is_training=True):\n",
    "    \"\"\"Load and parse dataset.\n",
    "    Args:\n",
    "        filenames: list of image paths\n",
    "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
    "        is_training: boolean to indicate training mode\n",
    "    \"\"\"\n",
    "    filenames = np.asarray(filenames)\n",
    "    labels = np.asarray(labels)\n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    print(dataset.element_spec)\n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if is_training == True:\n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        dataset = dataset.cache()\n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "        \n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = os.path.join('..','..','data_tate')\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "labels = []\n",
    "for i,img_targ in enumerate(img_target):\n",
    "    img_targ0 = str(img_targ[0])+'_8.jpg'\n",
    "    if img_targ0 in onlyfiles:\n",
    "        filenames.append(str(img_targ[0])+'_8.jpg')\n",
    "        labels.append(img_targ[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24999\n"
     ]
    }
   ],
   "source": [
    "filenames = [os.path.join('..','..','data_tate',str(filename)) \\\n",
    "                 for filename in filenames]\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('filenames.pkl', 'wb') as outfile:\n",
    "    pickle.dump(filenames, outfile)\n",
    "    \n",
    "with open('labels.pkl', 'wb') as outfile2:\n",
    "    pickle.dump(labels, outfile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24999 24999\n"
     ]
    }
   ],
   "source": [
    "with open('filenames.pkl', 'rb') as infile:\n",
    "    filenames = pickle.load(infile)\n",
    "    \n",
    "with open('labels.pkl', 'rb') as infile2:\n",
    "    labels = pickle.load(infile2)\n",
    "    \n",
    "print(len(filenames), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(16,), dtype=tf.float64, name=None))\n",
      "Tensor(\"DecodeJpeg:0\", shape=(None, None, 3), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 224, 224, 3), (None, 16)), types: (tf.float32, tf.float64)>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = create_dataset(filenames, labels)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                         input_shape=(IMG_SIZE,IMG_SIZE,CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    tf.keras.layers.Dense(1024, activation='relu', name='hidden_layer'),\n",
    "    tf.keras.layers.Dense(16, activation='sigmoid', name='output')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(y, y_hat, thresh=0.5):\n",
    "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        thresh: probability value above which we predict positive\n",
    "        \n",
    "    Returns:\n",
    "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
    "    \"\"\"\n",
    "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
    "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
    "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
    "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
    "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    macro_f1 = tf.reduce_mean(f1)\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-5 # Keep it small when transfer learning\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "  loss=tf.keras.losses.binary_crossentropy,\n",
    "  metrics=[macro_f1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "98/98 [==============================] - 1065s 11s/step - loss: 0.5584 - macro_f1: 0.1676\n",
      "Epoch 2/30\n",
      "98/98 [==============================] - 1008s 10s/step - loss: 0.4540 - macro_f1: 0.1414\n",
      "Epoch 3/30\n",
      "98/98 [==============================] - 997s 10s/step - loss: 0.4270 - macro_f1: 0.1722\n",
      "Epoch 4/30\n",
      "98/98 [==============================] - 994s 10s/step - loss: 0.4088 - macro_f1: 0.2008\n",
      "Epoch 5/30\n",
      "98/98 [==============================] - 1008s 10s/step - loss: 0.3949 - macro_f1: 0.2204\n",
      "Epoch 6/30\n",
      "98/98 [==============================] - 1005s 10s/step - loss: 0.3845 - macro_f1: 0.2371\n",
      "Epoch 7/30\n",
      "79/98 [=======================>......] - ETA: 3:23:30 - loss: 0.3822 - macro_f1: 0.2484"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-46ea13b70ea9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m history = model.fit(train_ds,\n\u001b[1;32m----> 2\u001b[1;33m   epochs=EPOCHS,)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "  epochs=EPOCHS,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.read_file(os.path.join('..','..','data_tate','A00001_8.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
